<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Coursera ml : Project Assignment Write Up">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Coursera ml</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/TimG333/Coursera_ML">View on GitHub</a>

          <h1 id="project_title">Coursera ml</h1>
          <h2 id="project_tagline">Project Assignment Write Up</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/TimG333/Coursera_ML/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/TimG333/Coursera_ML/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>Coursera_ML / ml.html
TimG333TimG333 27 minutes ago Uploading Assignment
1 contributor
189 lines (164 sloc)  455.559 kb RawBlameHistory<br>
&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p></p>

<p></p>

<p></p>Machine Learning Project<p></p>

code{white-space: pre;}<p></p>


  pre:not([class]) {
    background-color: white;
  }
<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
<div>


<div>
<h1>
<a name="machine-learning-project" class="anchor" href="#machine-learning-project"><span class="octicon octicon-link"></span></a>Machine Learning Project</h1>
<h4>
<a name="timothy-groth" class="anchor" href="#timothy-groth"><span class="octicon octicon-link"></span></a><em>Timothy Groth</em>
</h4>
<h4>
<a name="sunday-september-21-2014" class="anchor" href="#sunday-september-21-2014"><span class="octicon octicon-link"></span></a><em>Sunday, September 21, 2014</em>
</h4>
</div>

<div>
<h1>
<a name="data-and-package-loading" class="anchor" href="#data-and-package-loading"><span class="octicon octicon-link"></span></a>Data and Package Loading</h1>
<p>Data is read in, packages are loaded.</p>
<pre><code>library("caret")</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>library("ada")</code></pre>
<pre><code>## Loading required package: rpart</code></pre>
<pre><code>library("randomForest")</code></pre>
<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>exploreassignment &lt;- read.csv("pml-training.csv")</code></pre>
</div>

<div>
<h1>
<a name="initial-considerations" class="anchor" href="#initial-considerations"><span class="octicon octicon-link"></span></a>Initial Considerations</h1>
<p>Initial exploration of the data and its source indicates a great deal of variables with many NAs. These variables are dropped as they will not be as useful predictors. As a note these are the summary metrics derived from the more direct observations that remain. Some factor variables that do not have NAs but have similar issues and are also summary metrics are similarly dropped.</p>
<p>Variables of identification were also removed due to a priori assumption of irrelevance.</p>
<pre><code>exclude &lt;- grep("^amplitude",names(exploreassignment))
workingSet &lt;- exploreassignment[,-exclude]
exclude &lt;- grep("^var",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^avg",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^min",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^max",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^stddev",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^skewness", names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("X",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("user_name",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^kurtosis",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("^cvtd", names(workingSet))
workingSet &lt;- workingSet[,-exclude]
exclude &lt;- grep("window$",names(workingSet))
workingSet &lt;- workingSet[,-exclude]
finalKeep &lt;- names(workingSet)</code></pre>
<p>After the previously mentioned variables are dropped, the data is split into test and training sets. This is done after the initial data cleaning as the initial procedure was as much about the practicalities of handling the data on avaiable hardware as actual analysis. In more optimal conditions the summary variables would be dealt with as part of the dataset and training, and excluded in that way.</p>
<pre><code>set.seed(54321)
inTrain &lt;- createDataPartition(workingSet$classe, p=3/4, list=FALSE)
training &lt;- workingSet[inTrain,]
testing &lt;- workingSet[-inTrain,]</code></pre>
<p>With a clean training set to look at, some exploratory work was done. There is good reason to assume there may be correlation between predictors, particular in that the wrist and weight are both monitored for position and these seem like they would be naturally connected–and connected in a way that is relevant to predicting certain classes of incorrect exercise execution. This suggests PCA as an option to getting meaningful information. We do indeed see that 54 predictors can be reduced to 19 and still explain 90% of the variance among the predictor variables.</p>
<pre><code>PCA &lt;- prcomp(training[,-55], scale.=TRUE)
plot(PCA)</code></pre>
<p><img title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="672"></p>
<p>As an aside, due to the constraints of the assignment a random forest model was used to maximize predictability. While this may make interpreting the model more difficult, it is likely to improve predictive ability. It may also be possible to use such a model to understand why a set of motions is triggeirng an incorrect performance class (which would be ideal in a practical situation, as simply indicating it is wrong does not provide sufficient feedback to correct the issue).</p>
<pre><code> set.seed(54321)
baseModel &lt;- train(classe ~ . , data=training)
baseModel$finalModel</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 28
## 
##         OOB estimate of  error rate: 0.22%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4184    1    0    0    0   0.0002389
## B    5 2841    2    0    0   0.0024579
## C    0    6 2557    4    0   0.0038956
## D    0    0    7 2403    2   0.0037313
## E    0    0    3    2 2701   0.0018477</code></pre>
<p>Due to the predicted perfomance of the PCA free model and the processor constraints, no PCA model was built into this report.</p>
</div>

<div>
<h1>
<a name="cross-validation" class="anchor" href="#cross-validation"><span class="octicon octicon-link"></span></a>Cross Validation</h1>
<p>The random forest method for caret’s train function includes built in cross validation (holding cases in reserve to test built trees with). As noted above the estimated error rate is .22%.</p>
<p>Applying to the reserved testing data we see that it, as expected, yields a higher eror rate of .99%.</p>
<pre><code>baseResults &lt;- predict(baseModel,testing)
table(baseResults,testing$classe)</code></pre>
<pre><code>##            
## baseResults    A    B    C    D    E
##           A 1395    2    0    0    0
##           B    0  947    0    0    0
##           C    0    0  852    1    0
##           D    0    0    3  802    1
##           E    0    0    0    1  900</code></pre>
<pre><code>sum(baseResults == testing$classe)/length(baseResults)</code></pre>
<pre><code>## [1] 0.9984</code></pre>
</div>

<div>
<h1>
<a name="final-testing" class="anchor" href="#final-testing"><span class="octicon octicon-link"></span></a>Final Testing</h1>
<p>Running the code from the course site to generate files to submit. Which went well.</p>
<pre><code>pml_write_files = function(x){
  n = length(x)
   for(i in 1:n){
     filename = paste0("problem_id_",i,".txt")
     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
     }
  }
check &lt;- read.csv("pml-testing.csv")
finalResults &lt;- predict(baseModel,check)
pml_write_files(finalResults)</code></pre>
</div>

<p></p>
</div>

<p>
</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Coursera ml maintained by <a href="https://github.com/TimG333">TimG333</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
